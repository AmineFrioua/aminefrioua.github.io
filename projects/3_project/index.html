<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Creating my own Neural Network | Software Engineer</title>
    <meta name="author" content="Mohamed Amine  Frioua">
    <meta name="description" content="playing with matrix for fun">
    <meta name="keywords" content="Amine Frioua, Mohamed Amine Frioua, Ramdoyen, Venators">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://aminefrioua.github.io/projects/3_project/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="//">Software Engineer</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Creating my own Neural Network</h1>
            <p class="post-description">playing with matrix for fun</p>
          </header>

          <article>
            <h1 id="building-a-neural-network-from-scratch">Building a Neural Network from Scratch</h1>
<p>As someone interested in machine learning and artificial intelligence, I’ve always been fascinated by the inner workings of neural networks. While there are plenty of pre-built models and frameworks available, I wanted to take on the challenge of building a neural network from scratch, both as a fun coding project and to deepen my understanding of the underlying theory.</p>

<h2 id="the-basics-of-neural-networks">The Basics of Neural Networks</h2>
<p>Before diving into the coding, let’s review some of the basics of neural networks. At a high level, a neural network is a computational model inspired by the structure and function of the human brain. It’s made up of individual neurons that are connected in layers, with each layer processing information and passing it on to the next.</p>

<p>The first layer, called the input layer, takes in the raw data. The output layer produces the final predictions or classifications, and the layers in between are known as hidden layers. Each neuron in the network takes in a set of input values, multiplies them by a set of weights, adds a bias term, and passes the result through an activation function. The activation function determines whether the neuron “fires” or not based on the input, weights, and bias.</p>

<p>During training, the network adjusts the weights and biases of the neurons in order to minimize the difference between the predicted outputs and the actual outputs. This process is known as backpropagation, and it involves computing the gradient of the loss function with respect to the weights and biases, and then updating them in the direction of the gradient.</p>

<h2 id="building-the-network">Building the Network</h2>
<p>Now that we have a basic understanding of neural networks, let’s start building our own. For this project, I’ll be using Python and the NumPy library for numerical computing.</p>

<p>First, we’ll define a class for our neural network. Our network will take in a set of input values, process them through a set of hidden layers, and produce a set of output values. We’ll start by defining the basic structure of the network, including the number of input and output nodes, the number of hidden layers, and the number of neurons in each layer.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">,</span> <span class="n">hidden_nodes</span><span class="p">,</span> <span class="n">output_nodes</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_nodes</span> <span class="o">=</span> <span class="n">hidden_nodes</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_nodes</span> <span class="o">=</span> <span class="n">output_nodes</span>
        <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">weights_input_hidden</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
                                                     <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_nodes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">input_nodes</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">output_nodes</span><span class="o">**-</span><span class="mf">0.5</span><span class="p">,</span> 
                                                      <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">output_nodes</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_nodes</span><span class="p">))</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>


</code></pre></div></div>

<p>In the <strong>init</strong> method, we initialize the input, hidden, and output nodes, as well as the learning rate. We also randomly initialize the weights between the input layer and the first hidden layer, and between the last hidden layer and the output layer.</p>

<p>We define the sigmoid activation function as a lambda function, since we’ll be using it multiple times in the network.</p>

<p>Next, we’ll define the train method, which will take in a set of input values and target values, and update the weights and biases of the network using backpropagation.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs_list</span><span class="p">,</span> <span class="n">targets_list</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">inputs_list</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">T</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">targets_list</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">T</span>
    
    <span class="n">hidden_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_input_hidden</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">hidden_inputs</span><span class="p">)</span>
    
    <span class="n">final_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span><span class="p">,</span> <span class="n">hidden_outputs</span><span class="p">)</span>
    <span class="n">final_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">final_inputs</span><span class="p">)</span>
    
    <span class="n">output_errors</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">-</span> <span class="n">final_outputs</span>
    <span class="n">hidden_errors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">output_errors</span><span class="p">)</span>
    
    <span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">((</span><span class="n">output_errors</span> <span class="o">*</span> <span class="n">final_outputs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">final_outputs</span><span class="p">)),</span>
                                                              <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">hidden_outputs</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="n">weights_input_hidden</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">((</span><span class="n">hidden_errors</span> <span class="o">*</span> <span class="n">hidden_outputs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">hidden_outputs</span><span class="p">)),</span>
                                                             <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>


</code></pre></div></div>

<p>In the train method, we start by converting the input and target values into NumPy arrays. We then perform forward propagation, computing the outputs of the hidden and output layers. We calculate the errors at each layer by comparing the target values with the actual outputs.</p>

<p>Next, we update the weights and biases using backpropagation. We compute the gradient of the loss function with respect to the weights between the hidden and output layers, and between the input and hidden layers. Finally, we update the weights by multiplying the gradients with the learning rate and the corresponding layer outputs.</p>

<p>To make predictions with our neural network, we’ll define the predict method:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs_list</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">inputs_list</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">T</span>
    
    <span class="n">hidden_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_input_hidden</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">hidden_inputs</span><span class="p">)</span>
    
    <span class="n">final_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span><span class="p">,</span> <span class="n">hidden_outputs</span><span class="p">)</span>
    <span class="n">final_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">final_inputs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">final_outputs</span>
</code></pre></div></div>

<p>In the predict method, we perform forward propagation to compute the final outputs of the network based on the given input values. We return the final outputs as our predictions.</p>

<h2 id="testing-the-neural-network">Testing the Neural Network</h2>
<p>Now that we’ve defined our neural network class, let’s test it on a simple problem. We’ll create a neural network that can predict whether a given person is male or female based on their height, weight, and age.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a neural network with 3 input nodes, 2 hidden nodes, and 1 output node
</span><span class="n">network</span> <span class="o">=</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Train the network using a set of example inputs and targets
</span><span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">170</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="p">[</span><span class="mi">180</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span> <span class="p">[</span><span class="mi">150</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">20</span><span class="p">]]</span>
<span class="n">training_targets</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_targets</span><span class="p">):</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

<span class="c1"># Test the network by making predictions on new inputs
</span><span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">175</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">27</span><span class="p">],</span> <span class="p">[</span><span class="mi">165</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">35</span><span class="p">],</span> <span class="p">[</span><span class="mi">185</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="mi">42</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">test_inputs</span><span class="p">:</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"Prediction:"</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>

    <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">hidden_inputs</span><span class="p">)</span>
    
    <span class="n">final_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span><span class="p">,</span> <span class="n">hidden_outputs</span><span class="p">)</span>
    <span class="n">final_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">final_inputs</span><span class="p">)</span>

    <span class="n">output_errors</span> <span class="o">=</span> <span class="n">targets</span> <span class="o">-</span> <span class="n">final_outputs</span>
    <span class="n">hidden_errors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">output_errors</span><span class="p">)</span>
    
    <span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">((</span><span class="n">output_errors</span> <span class="o">*</span> <span class="n">final_outputs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">final_outputs</span><span class="p">)),</span>
                                                              <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">hidden_outputs</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="n">weights_input_hidden</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">((</span><span class="n">hidden_errors</span> <span class="o">*</span> <span class="n">hidden_outputs</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">hidden_outputs</span><span class="p">)),</span>
                                                             <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
</code></pre></div></div>

<p>In the train method, we start by converting the input and target values into NumPy arrays. We then perform forward propagation, computing the outputs of the hidden and output layers. We calculate the errors at each layer by comparing the target values with the actual outputs.</p>

<p>Next, we update the weights and biases using backpropagation. We compute the gradient of the loss function with respect to the weights between the hidden and output layers, and between the input and hidden layers. Finally, we update the weights by multiplying the gradients with the learning rate and the corresponding layer outputs.</p>

<p>To make predictions with our neural network, we’ll define the predict method:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs_list</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">inputs_list</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">T</span>
    
    <span class="n">hidden_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_input_hidden</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="n">hidden_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">hidden_inputs</span><span class="p">)</span>
    
    <span class="n">final_inputs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights_hidden_output</span><span class="p">,</span> <span class="n">hidden_outputs</span><span class="p">)</span>
    <span class="n">final_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">final_inputs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">final_outputs</span>
</code></pre></div></div>

<p>In the predict method, we perform forward propagation to compute the final outputs of the network based on the given input values. We return the final outputs as our predictions.</p>

<p>Testing the Neural Network
Now that we’ve defined our neural network class, let’s test it on a simple problem. We’ll create a neural network that can predict whether a given person is male or female based on their height, weight, and age.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a neural network with 3 input nodes, 2 hidden nodes, and 1 output node
</span><span class="n">network</span> <span class="o">=</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Train the network using a set of example inputs and targets
</span><span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">170</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="p">[</span><span class="mi">180</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span> <span class="p">[</span><span class="mi">150</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">20</span><span class="p">]]</span>
<span class="n">training_targets</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_targets</span><span class="p">):</span>
        <span class="n">network</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

<span class="c1"># Test the network by making predictions on new inputs
</span><span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">175</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">27</span><span class="p">],</span> <span class="p">[</span><span class="mi">165</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">35</span><span class="p">],</span> <span class="p">[</span><span class="mi">185</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="mi">42</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">test_inputs</span><span class="p">:</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"Prediction:"</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>

<p>In this example, we train the network using a set of example inputs and targets. We iterate through the training data multiple times, updating the weights and biases after each iteration. After training, we test the network by making predictions on new inputs.</p>

<h2 id="conclusion">Conclusion</h2>
<p>Building a neural network from scratch has been a rewarding experience. It has deepened my understanding of the inner workings of neural networks, from the basics of neuron activation to the backpropagation algorithm for training. By implementing a neural network from scratch, I gained insights into the key concepts and challenges involved in designing and training a neural network.
While this neural network implementation is basic and not optimized for performance, I had fun while building this project and that is what matter ( plus all the benefits from learning).
now here is your cookie for reading this or scrolling down.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/6-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/6-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/6-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/6.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>


          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Mohamed Amine  Frioua. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
